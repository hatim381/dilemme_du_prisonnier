# ğŸ® Dilemme du Prisonnier : IA vs StratÃ©gies CodÃ©es

**Analyse narrative complÃ¨te** des comportements Ã©mergents quand agents gÃ©nÃ©ratifs (LLM) rencontrent stratÃ©gies dÃ©terministes dans le classique **Prisoner's Dilemma**.

> Exploration empirique de la coopÃ©ration, de l'apprentissage implicite, et des Ã©quilibres observÃ©s chez les modÃ¨les de langage vs. stratÃ©gies optimales codÃ©es.

---

## ğŸ“š Table des MatiÃ¨res

1. [Vue d'ensemble](#vue-densemble)
2. [DÃ©marrage rapide](#dÃ©marrage-rapide)
3. [Architecture du projet](#architecture-du-projet)
4. [Installation & Configuration](#installation--configuration)
5. [ExÃ©cution](#exÃ©cution)
6. [Structure des donnÃ©es](#structure-des-donnÃ©es)
7. [Dashboard Streamlit](#dashboard-streamlit)
8. [RÃ©sultats clÃ©s](#rÃ©sultats-clÃ©s)
9. [Customisation](#customisation)

---

## ğŸ‘ï¸ Vue d'ensemble

### ğŸ¯ Objectif

Comparer et analyser les **stratÃ©gies Ã©mergentes** dans le dilemme du prisonnier rÃ©pÃ©tÃ© :

| Aspect | IA (Qwen, Gemma) | CodÃ© |
|--------|---|---|
| **Comportement** | Adaptatif, sensible contexte | DÃ©terministe, prÃ©-dÃ©fini |
| **VariabilitÃ©** | TempÃ©rature, context-aware | Aucune variation |
| **Apprentissage** | Implicite dans les tokens | Pas d'apprentissage |

### â“ Questions de recherche

- âœ“ La coopÃ©ration Ã©merge-t-elle naturellement par rÃ©pÃ©tition ? (hypothÃ¨se Axelrod)
- âœ“ L'IA suit-elle les rÃ´les assignÃ©s ou Ã©merge-t-elle des stratÃ©gies propres ?
- âœ“ Impact de la tempÃ©rature et du contexte sur les comportements IA ?
- âœ“ Comment les Ã©quilibres observÃ©s se comparent-ils Ã  Nash/Pareto ?

### ğŸ“Š Dataset en bref

- **283,200 rounds** Ã  travers **1,416 matchs**
- **17 agents distincts** (combinaisons famille Ã— rÃ´le)
- Distribution : ~62% Qwen, ~21% Gemma, ~17% CodÃ©
- **29 colonnes** : coopÃ©ration, scores, tempÃ©rature, contexte, conformitÃ©, etc.
- Taille : ~180 MB (enriched_games_full.parquet)
---

## âš¡ DÃ©marrage rapide

```bash
# 1. Cloner et installer
git clone https://github.com/hatim381/dilemme_du_prisonnier.git
cd dilemme_du_prisonnier
pip install -r requirements.txt

# 2. Lancer le dashboard
streamlit run streamlit_report.py

# 3. Ouvrir dans le navigateur
# http://localhost:8501
```


```
dilemme_du_prisonnier/
â”‚
â”œâ”€â”€ ğŸ¯ POINT D'ENTRÃ‰E
â”‚   â””â”€â”€ streamlit_report.py              â­ Dashboard analytique (7 pages narratives)
â”‚
â”œâ”€â”€ ğŸ® MOTEUR & EXPÃ‰RIENCES
â”‚   â”œâ”€â”€ game_engine.py                   Logique jeu (payoffs, rounds, matchs)
â”‚   â”œâ”€â”€ run_experiment.py                Lancer expÃ©riences uniques
â”‚   â””â”€â”€ run_batch_parallel_turbo.py      ExÃ©cution parallÃ¨le multiprocessing
â”‚
â”œâ”€â”€ ğŸ““ NOTEBOOKS
â”‚   â””â”€â”€ transform.ipynb                  Transformation & exploration donnÃ©es
â”‚
â”œâ”€â”€ ğŸ’¾ DATA
â”‚   â””â”€â”€ enriched_data/
â”‚       â””â”€â”€ enriched_games_full.parquet  283,200 rows Ã— 29 colonnes
â”‚
â”œâ”€â”€ ğŸ“Š RÃ‰SULTATS
â”‚   â””â”€â”€ results/                         Outputs bruts (.parquet)
â”‚
â””â”€â”€ ğŸ“– DOCUMENTATION
    â”œâ”€â”€ README.md                        â† Vous Ãªtes ici
    â”œâ”€â”€ README_parallel.md               Guide parallÃ©lisation
    â””â”€â”€ Lien_sujet_notion.txt            Sujet complet (Notion)
```

**Fichiers essentiels :**
- â­ `streamlit_report.py` â€” **Ã€ lancer en prioritÃ©**
- ğŸ’¾ `enriched_data/enriched_games_full.parquet` â€” Source donnÃ©es principale
- ğŸ““ `transform.ipynb` â€” Transformation & analyses donnÃ©es

---

## ğŸš€ Installation & Configuration

### PrÃ©requis

- **Python 3.9+**
- pip ou conda
- ~2GB disque libre (donnÃ©es)

### Ã‰tapes d'installation

```bash
# 1ï¸âƒ£ Cloner le repo
git clone https://github.com/hatim381/dilemme_du_prisonnier.git
cd dilemme_du_prisonnier

# 2ï¸âƒ£ CrÃ©er environnement virtuel
python -m venv .venv
source .venv/bin/activate              # Linux/Mac
# ou
.venv\Scripts\activate                 # Windows

# 3ï¸âƒ£ Installer dÃ©pendances
pip install -r requirements.txt

# 4ï¸âƒ£ VÃ©rifier les donnÃ©es
python -c "import pandas as pd; df = pd.read_parquet('enriched_data/enriched_games_full.parquet'); print(f'âœ“ Loaded: {df.shape[0]:,} rows Ã— {df.shape[1]} cols')"
```

---

## âš™ï¸ ExÃ©cution

### 1ï¸âƒ£ Dashboard Streamlit (RecommandÃ©)

```bash
streamlit run streamlit_report.py
```

ğŸ‘‰ **Ouvrir** : http://localhost:8501

#### ğŸ“– Les 7 Pages du Dashboard

| # | Page | Contenu |
|---|------|---------|
| 1 | ğŸŒ **Vue Globale** | Architecture gÃ©nÃ©rale, leaderboard agents, KPIs |
| 2 | ğŸ¤ **CoopÃ©ration & Motifs** | Taux par type, tempÃ©rature, contexte, agent (4 tabs) |
| 3 | ğŸ† **Performance & EfficacitÃ©** | Scores, corrÃ©lations, variabilitÃ©, effets |
| 4 | ğŸŒ¡ï¸ **Facteurs IA** | TempÃ©rature, modÃ¨le, contexte (heatmaps) |
| 5 | âš¡ **Dynamique Temporelle** | Ã‰volution coopÃ©ration par round, phases Ã©mergentes |
| 6 | ğŸ“ˆ **ThÃ©orie & Ã‰quilibres** | Matrice CC/CD/DC/DD, Nash vs. observÃ© |
| 7 | ğŸ¯ **SynthÃ¨se Finale** | Comparaison IA vs. CodÃ©, insights clÃ©s, recommandations |

---

### 2ï¸âƒ£ Notebook Transformation & Analyses


```bash
jupyter notebook transform.ipynb
```

**Contient :**
- Chargement & inspection des donnÃ©es (schÃ©ma, types)
- Transformations & features dÃ©rivÃ©es
- Analyses descriptives (coop rates, scores, variance)
- Clustering comportemental & profils d'agents
- Analyses IA : tempÃ©rature, contexte, modÃ¨le
- Dynamiques temporelles et stabilitÃ©

---

### 3ï¸âƒ£ RÃ©-exÃ©cuter les expÃ©riences

```bash
# ExpÃ©rience simple (1 seed)
python run_experiment.py

# Batch parallÃ¨le optimisÃ© (multiprocessing)
python run_batch_parallel_turbo.py
```

ğŸ‘‰ Consulter `README_parallel.md` pour l'optimisation avancÃ©e

---

## ğŸ“Š Structure des donnÃ©es

### AperÃ§u

| MÃ©trique | Valeur |
|----------|--------|
| Nombre de lignes | 283,200 rounds |
| Nombre de colonnes | 29 features |
| Nombre de matchs | 1,416 |
| Nombre d'agents distincts | 17 |
| Taille du fichier | ~180 MB (parquet) |
| PÃ©riode de collecte | ComplÃ¨te |

### Colonnes principales (29 total)

**Identifiants & Structure**
- `match_id` : Identifiant unique du match
- `round_id` : NumÃ©ro du round dans le match

**Agent 1 (& idem pour Agent 2)**
- `agent1_name` : Nom (famille + rÃ´le, ex: "Qwen_Cooperator")
- `agent1_family` : Famille ("qwen", "gemma", "coded")
- `agent1_is_cooperation` : Mouvement (1=CoopÃ©ration, 0=DÃ©fection)
- `agent1_match_score` : Score du round (0-1000)
- `agent1_temperature_bucket` : TempÃ©rature ("low", "medium", "high", "coded")
- `agent1_context_used_flag` : Contexte fourni (1=oui, 0=non)
- `agent1_conformity_score` : Alignement rÃ´le (0-1)

**Features dÃ©rivÃ©es (dans Streamlit)**
```python
df["agent1_move"] = df["agent1_is_cooperation"].map({1: "C", 0: "D"})
df["agent1_is_ia"] = df["agent1_family"].str.contains("qwen|gemma")
df["outcome"] = df["agent1_move"] + df["agent2_move"]  # CC, CD, DC, DD
df["total_score"] = df["agent1_match_score"] + df["agent2_match_score"]
```

---

## ğŸ“ˆ Dashboard Streamlit â€“ DÃ©tails

### Page 1 : ğŸŒ Vue Globale

**MÃ©triques clÃ©s (KPIs) :**
- Total mouvements IA / CodÃ©s
- Taux coopÃ©ration global par type
- Nombre de rounds/matchs

**Visualisations :**
- ğŸ“Š Distribution rounds par famille (bar chart)
- ğŸ† Top 15 agents par score moyen (horizontal bar chart)

---

### Page 2 : ğŸ¤ CoopÃ©ration & Motifs

**4 onglets interactifs :**
1. **Par type d'agent** : Taux coop Qwen vs. Gemma vs. CodÃ©
2. **Par tempÃ©rature** : Impact low/medium/high sur coopÃ©ration (IA uniquement)
3. **Par contexte** : Avec/sans prompting fourni
4. **Par agent** : DÃ©tail individuel (17 agents)

**Visualisation** : Pie charts + barplots avec tendances

---

### Page 3 : ğŸ† Performance & EfficacitÃ©

**3 onglets :**
1. **Score moyen** : Bar chart avec std deviation
2. **Score vs CoopÃ©ration** : Scatter plot (rÃ©vÃ¨le non-linÃ©aritÃ©)
3. **VariabilitÃ©** : Boxplot distribution scores par type

**Insight clÃ©** : Pas de corrÃ©lation linÃ©aire score â†” coopÃ©ration

---

### Page 4 : ğŸŒ¡ï¸ Facteurs IA

**Exploration paramÃ¨tres IA :**
- **Heatmap** : TempÃ©rature Ã— ConformitÃ©
- **Comparaison** : Qwen vs. Gemma (coopÃ©ration, score, stabilitÃ©)
- **Contexte** : Impact contexte â†’ Score et CoopÃ©ration (2 bar charts)

---

### Page 5 : âš¡ Dynamique Temporelle

**Ã‰volution par round :**
- ğŸ“ˆ Ligne agent 1 & agent 2 coopÃ©ration + moving average
- ğŸ” Identification phases : Amorce â†’ Exploration â†’ Stabilisation â†’ Ã‰quilibre
- ğŸ“Š Patterns d'Ã©mergence

---

### Page 6 : ğŸ“ˆ ThÃ©orie & Ã‰quilibres

**Axelrod revisitÃ© :**
- **Heatmap** : FrÃ©quences outcomes CC/CD/DC/DD
- **Scatter** : CoopÃ©ration vs. Score + trend line
- **Analyse** : Ã‰quilibre observÃ© vs. Nash vs. Pareto optimum

---

### Page 7 : ğŸ¯ SynthÃ¨se Finale

**Tableau comparatif + Insights narratifs**
- ğŸ“Š CodÃ© vs. IA : transparent/stable vs. opaque/variable
- ğŸ”‘ **4 insights structurÃ©s** :
  1. RÃ´le du modÃ¨le LLM
  2. Impact tempÃ©rature & contexte
  3. Dynamique d'apprentissage implicite
  4. Implications thÃ©oriques
- ğŸ’¡ Recommandations pratiques

---

## ğŸ“ Fichiers principaux

### `streamlit_report.py` (1000+ lignes)
Dashboard production avec 7 pages narratives, soft color palette (#6B9BD1, #A8B39F), custom CSS.

### `game_engine.py`
Moteur du jeu : logique interaction agents, calcul payoffs, gestion rounds/matchs.

### `run_experiment.py`
Launcher simple pour expÃ©riences uniques. Arguments CLI pour configurer agents/rounds.

### `run_batch_parallel_turbo.py`
ExÃ©cution parallÃ¨le optimisÃ©e avec `multiprocessing.Pool`. GÃ¨re batches agents automatiquement.

### `transform.ipynb`
Notebook de transformation & exploration :
- Chargement & inspection donnÃ©es (schÃ©ma, types)
- Transformations features (dÃ©rivÃ©es, agrÃ©gations)
- Analyses descriptives (coop rates, scores, variance)
- Profils comportementaux (clustering)
- Analyses spÃ©cifiques IA (tempÃ©rature, contexte)
- Dynamiques temporelles & stabilitÃ©

---

## ğŸ¯ RÃ©sultats clÃ©s

### CoopÃ©ration par type d'agent

| Type | Taux CoopÃ©ration | Contexte |
|------|---|---|
| **Qwen** | ~56% | âœ… ModÃ¨le stable, coopÃ©ratif |
| **Gemma** | ~34% | âš ï¸ ModÃ¨le moins coopÃ©ratif |
| **CodÃ©** | ~55% | âœ… DÃ©terministe, proche Qwen |

**ğŸ’¡ Insight** : Le modÃ¨le LLM influe **plus** que le rÃ´le spÃ©cifiÃ©. Qwen Ã©merge naturellement coopÃ©ratif malgrÃ© contexte neutre.

---

### Performance & EfficacitÃ©

**Observation clÃ© :** âŒ **Pas de corrÃ©lation linÃ©aire** entre coopÃ©ration et score

- Agents optimaux : **coopÃ©ration modÃ©rÃ©e + rÃ©activitÃ© stratÃ©gique**
- Distribution outcomes observÃ©e : 
  - ~40% CC (mutual cooperation)
  - ~47% DD (mutual defection)
  - ~13% CD + DC (mixed)
- **87% d'Ã©tats "purs"** (CC ou DD) â†’ peu de patterns mixtes stables

---

### Dynamique temporelle

- âœ… CoopÃ©ration **stable** (variation < 5% entre dÃ©but/fin)
- ğŸ”„ **Phases distinctes** :
  1. Amorce (rounds 1-5)
  2. Exploration (rounds 6-15)
  3. Stabilisation (rounds 16-25)
  4. Ã‰quilibre (rounds 26+)
- âŒ **Pas d'Ã©mergence progressive Axelrod-like** (pas d'apprentissage visible)

---

### Facteurs IA (TempÃ©rature & Contexte)

| Facteur | Impact | Observation |
|---------|--------|---|
| **TempÃ©rature** | VariabilitÃ© â†‘ | CrÃ©e variance, rÃ©duit conformitÃ© au rÃ´le |
| **Contexte fourni** | CoopÃ©ration â†‘ | +5 Ã  10% quand prompting explicite |
| **ModÃ¨le (Qwen vs Gemma)** | StabilitÃ© â†‘ | Qwen > Gemma en adaptabilitÃ© |

**Implication** : L'IA a une "prÃ©fÃ©rence induite" pour la coopÃ©ration, rÃ©activitÃ© au contexte mais pas d'apprentissage explicite par round.

---

## ğŸ› ï¸ Customisation & DÃ©veloppement

### Modifier les couleurs du dashboard

Ã‰diter le dictionnaire `COLORS` dans `streamlit_report.py` (ligne ~15) :

```python
COLORS = {
    "blue": "#6B9BD1",      # Bleu principal
    "green": "#A8B39F",     # Vert foncÃ©
    "red": "#D5636D",       # Rouge
    "yellow": "#E3B448",    # Jaune
    # ... ajouter/modifier couleurs
}
```

### Ajouter une nouvelle page d'analyse

```python
# Dans streamlit_report.py

st.sidebar.title("Navigation")
page = st.sidebar.radio("Choisir page", ["Page 1", "Page N"])

if page == "Page N":
    # 1. Charger donnÃ©es enrichies
    df = load_and_prepare_data()
    
    # 2. AgrÃ©gations/transformations
    data_agg = df.groupby("agent1_family")["agent1_is_cooperation"].mean()
    
    # 3. Visualisation Plotly
    fig = px.bar(data_agg, title="Mon analyse")
    st.plotly_chart(fig, use_container_width=True)
```

### Changer la source de donnÃ©es

Modifier le chemin du fichier parquet :

```python
# Dans load_and_prepare_data() fonction
def load_and_prepare_data():
    df = pd.read_parquet("enriched_data/enriched_games_full.parquet")
    # â†“ remplacer par votre chemin â†“
    # df = pd.read_parquet("path/to/your/data.parquet")
    return df
```

### ExÃ©cution parallÃ¨le avancÃ©e

Consulter `README_parallel.md` pour :
- Batch parallelization
- Multiprocessing Pool
- Gestion ressources & timeouts
- Benchmarks performance

---

## ğŸ“š RÃ©fÃ©rences thÃ©oriques

### Concepts clÃ©s

**Axelrod's Prisoner's Dilemma** (Axelrod, 1984)
- Ã‰tude du comportement coopÃ©ratif en rÃ©pÃ©tition
- StratÃ©gie "Tit-for-Tat" : imiter l'adversaire Ã  chaque round
- Ã‰mergence naturelle de coopÃ©ration sans communication
- ğŸ“– *The Evolution of Cooperation*

**Ã‰quilibres de Nash**
- Situation oÃ¹ aucun agent ne peut amÃ©liorer **seul** son gain
- Dilemme du prisonnier : Nash = (DD, DD) â†’ sous-optimal collectivement
- CC serait Pareto optimal mais instable

**TempÃ©rature (LLM)**
- ContrÃ´le la "crÃ©ativitÃ©" du modÃ¨le (0 = dÃ©terministe, 1+ = stochastique)
- Impact observÃ© : variabilitÃ© comportementale

**ConformitÃ© au rÃ´le**
- Score 0-1 mesurant alignement entre rÃ´le assignÃ© et actions rÃ©elles
- Indicateur de "suivi des instructions"

---

## ğŸ“ Support & FAQ

### â“ Questions frÃ©quentes

**Q: Comment relancer les expÃ©riences ?**
```bash
python run_batch_parallel_turbo.py  # Multiprocessing (recommandÃ©)
```
Voir `README_parallel.md` pour dÃ©tails.

---

**Q: Quels fichiers dois-je modifier pour adapter le code ?**
- `streamlit_report.py` â†’ Dashboard
- `game_engine.py` â†’ Logique jeu
- `run_experiment.py` â†’ ParamÃ¨tres expÃ©rience

---

**Q: OÃ¹ sont les rÃ©sultats bruts des expÃ©riences ?**
- `results/` â†’ Fichiers .parquet bruts
- `enriched_data/enriched_games_full.parquet` â†’ Dataset enrichi prÃªt pour analyse

---

**Q: Comment tracer un debug ?**
1. Consulter `transform.ipynb` pour exploration donnÃ©es
2. VÃ©rifier `game_engine.py` pour logique jeu
3. Ajouter `st.write()` dans `streamlit_report.py` pour inspection

---

### ğŸ› Troubleshooting

| ProblÃ¨me | Solution |
|----------|----------|
| `FileNotFoundError: enriched_games_full.parquet` | VÃ©rifier chemin donnÃ©es (relativement au pwd) |
| Streamlit ne dÃ©marre pas | VÃ©rifier port 8501 libre, relancer avec `--server.port 8502` |
| Erreur import `duckdb` | `pip install duckdb` |
| Memory error (283K rows) | Augmenter limite RAM ou filtrer donnÃ©es |

---

## ğŸ“„ Licence & Auteur

### Licence

Ce projet est **open source**. Libre d'utilisation, modification et distribution avec attribution.

### Auteur

**Bill H.** â€” Master Data Lakes & Data Integrations, EFREI Paris (2024-2025)

**Contact** : [GitHub](https://github.com/hatim381/)

---

## ğŸ”„ Historique & Statut

| Date | Statut | Notes |
|------|--------|-------|
| DÃ©cembre 2024 | âœ… **Production Ready** | Dashboard complet, donnÃ©es enrichies validÃ©es |
| DÃ©cembre 2025 | âœ… **Maintenu** | Documentation Ã  jour, tous fichiers prÃ©sents |

---

**Version**: 1.0  
**DerniÃ¨re mise Ã  jour**: DÃ©cembre 2025  
**Statut**: âœ… Stable & Fonctionnel
